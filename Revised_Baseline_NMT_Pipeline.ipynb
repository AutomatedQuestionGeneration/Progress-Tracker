{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_with_attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfbpjs2fgzuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390d8651-9bde-45dd-a08c-16c5d9f0dbfb"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOsMShvlg4ua"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load data set\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "ekR1LguKlkhv",
        "outputId": "ee18c9c9-62d2-401d-908e-e25412a0c3e0"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/AutomatedQuestionGeneration/train.xlsx\").drop(\"Unnamed: 0\",axis = 1)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>c_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>269.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>207.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>2003</td>\n",
              "      <td>526.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>166.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>276.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      index  ... c_id\n",
              "0  56be85543aeaaa14008c9063  ...    0\n",
              "1  56be85543aeaaa14008c9065  ...    0\n",
              "2  56be85543aeaaa14008c9066  ...    0\n",
              "3  56bf6b0f3aeaaa14008c9601  ...    0\n",
              "4  56bf6b0f3aeaaa14008c9602  ...    0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6_PbyxFmWI2"
      },
      "source": [
        "df = df[:1000]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjk6RgoFlkfX"
      },
      "source": [
        "context = df[\"context\"].apply(lambda x: x).tolist()\n",
        "target_ques = df[\"question\"].apply(lambda x: x).tolist()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGFAPnJ2lltX",
        "outputId": "13223aa4-2b80-43c1-d26f-7ddb03165b5c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKjEWl6WhZyk"
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\",\"¿\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  # remove extra space\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc58-K0XhdCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d6d69a-5b3e-49c4-9b6b-08fd38e1cd24"
      },
      "source": [
        "en_sentence = u\"Beyonce's last record was called Lemonade\"\n",
        "sp_sentence = u\"Beyonce was born in 1950\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode(\"UTF-8\"))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> beyonce s last record was called lemonade <end>\n",
            "<start> beyonce was born in <end>\n",
            "b'<start> beyonce was born in <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hw9ct4OhsRA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d8b2bed5-2d5c-4d0f-b94d-c52a60ebbc5a"
      },
      "source": [
        "# Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)\n",
        "\n",
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])\n",
        "print(len(en), len(sp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n",
            "118964 118964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSahzYVJm4zu",
        "outputId": "3b2a16d2-480d-4641-a6c6-11164d5732a2"
      },
      "source": [
        "def create_dataset_squad(context_param,target_ques):\n",
        "  context = []\n",
        "  question = []\n",
        "  for c,q in zip(context_param,target_ques):\n",
        "    context.append(preprocess_sentence(c))\n",
        "    question.append(preprocess_sentence(q))\n",
        "  return context, question\n",
        "\n",
        "c, q = create_dataset_squad(context,target_ques)\n",
        "print(c[-1])\n",
        "print(q[-1])\n",
        "print(len(c), len(q))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> two polish friends in paris were also to play important roles in chopin s life there . his fellow student at the warsaw conservatory , julian fontana , had originally tried unsuccessfully to establish himself in england albert grzyma a , who in paris became a wealthy financier and society figure , often acted as chopin s adviser and gradually began to fill the role of elder brother in his life . fontana was to become , in the words of micha owski and samson , chopin s general factotum and copyist . <end>\n",
            "<start> who is stated as a jack of all trades in service to frederic ? <end>\n",
            "1000 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCAYRuTlh5DY"
      },
      "source": [
        "# Tokenize the sentence into list of words(integers) and pad the sequence to the same length\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e13Aa8yliFkp"
      },
      "source": [
        "def load_dataset(input, target):\n",
        "  # creating cleaned input, output pairs\n",
        "  #targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(input)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(target)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EasB_FLig5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d00ef3-014e-4c9c-acfb-9a2ca5468d0b"
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "#num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(c,q)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "print(max_length_targ, max_length_inp)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30 358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oS6mqluirWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51261e7b-6b54-463c-b5ac-7d5eb367dadc"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
        "print(input_tensor_train[1])\n",
        "print()\n",
        "print(target_tensor_train[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800 800 200 200\n",
            "[  20   13  142    1    1   36   14  184   25    8   39    7  260  953\n",
            "    1   15  585   77   26  156    1    4    2   26  451  462  452    3\n",
            "    2  462 2473    4 2474 2475    5  293 1017   26 1018    3    8   10\n",
            "  630   63   64  949    2 2476  264    6  452    1 2477    1    4    2\n",
            "   27 2478    6    3   88    8    5   63   64    1 1060   50 2479  396\n",
            "   19  924  518    1 1021    1  435    1 1013  629    1 1022 1023    5\n",
            "  191  260  216  452    1   15    2 2480 2481    7 2482 2483    3    2\n",
            " 2484    6  296   34   65   50 2485  451  462   14  678   23  609 1096\n",
            "    9 2486    9    2 2487  548   12  451 2488    2 2489   26  267    1\n",
            "    5    9 2490   77  451 2491  396   19 2492    1   31  106  217 2493\n",
            "   12   32 2494 2495    6 2496    3    2 2497   39    9  362 2498    9\n",
            " 2499   26  631    1    9 2500   57 2501    1  374   63   64   13    2\n",
            "  161    6  452    3   21    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "\n",
            "[  1  14 737   5 352  61   9   5  41 174   4 744  78   9   3   2   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK3NE1vUityv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed08d43-9b00-4e15-d3fe-e53d02a361d2"
      },
      "source": [
        "# Configuration \n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "steps_per_epoch_val = len(input_tensor_val)//BATCH_SIZE\n",
        "embedding_dim = 256  # for word embedding\n",
        "units = 1024  # dimensionality of the output space of RNN\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(BUFFER_SIZE)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 358]), TensorShape([64, 30]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzo3ZvYpv4KE"
      },
      "source": [
        "# Seq2seq model: Encoder, Decoder with Additive Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFjq9Ta3wA8F"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,  # Whether to return the last output in the output sequence, or the full sequence. \n",
        "                                   return_state=True,  # Whether to return the last state in addition to the output.\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4GoRSHSwScu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b4422c-f850-47d5-a0ca-1d037ee42d28"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 358, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy6ualLHwYzY"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "    return x, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_z9vs5U06hk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8378e62d-e45e-4b2c-fc61-3109d2cea71b"
      },
      "source": [
        "# decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample_decoder_output, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "#                                       sample_hidden)\n",
        "\n",
        "# print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1-eiiJ_xyoM"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(query_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXqWOEGh9BAm"
      },
      "source": [
        "class DecoderWithAttention(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_layer = None):\n",
        "    super(DecoderWithAttention, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = attention_layer\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "    attention_weights = None\n",
        "    \n",
        "    if self.attention:\n",
        "      # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "      context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "      # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "      x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9oozBiV1Khj"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) \n",
        "  loss_ = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFLLiTBgnwG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b23cd95-b525-4e61-f3af-d8a77f990449"
      },
      "source": [
        "print(loss_object([1,2],[[0,0.6,0.3,0.1],[0,0.6,0.3,0.1]]))\n",
        "print(loss_function([1,2],[[0,0.6,0.3,0.1],[0,0.6,0.3,0.1]]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1.063386  1.3633859], shape=(2,), dtype=float32)\n",
            "tf.Tensor(1.2133859, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-KFHrDCyFff"
      },
      "source": [
        "# Training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz6c3l931TC8"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "def get_train_step_func():\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(inp, targ, enc_hidden, encoder, decoder):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape: # for automatic differentiation\n",
        "      enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "      dec_hidden = enc_hidden\n",
        "\n",
        "      dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "      # Teacher forcing - feeding the target as the next input\n",
        "      for t in range(1, targ.shape[1]):\n",
        "        # passing enc_output to the decoder\n",
        "        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "        loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "        # using teacher forcing\n",
        "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "    \n",
        "  return train_step\n",
        "    "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zym-buZ_TEg"
      },
      "source": [
        "def caculate_validation_loss(inp, targ, enc_hidden, encoder, decoder):\n",
        "  loss = 0\n",
        "  enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "  # Teacher forcing - feeding the target as the next input\n",
        "  for t in range(1, targ.shape[1]):\n",
        "    predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "    loss += loss_function(targ[:, t], predictions)\n",
        "    dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  loss = loss / int(targ.shape[1])\n",
        "  return loss"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMo0_PVaJiP7"
      },
      "source": [
        "def training_seq2seq(epochs, attention):\n",
        "  encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "  decoder = DecoderWithAttention(vocab_tar_size, embedding_dim, units, BATCH_SIZE, attention)\n",
        "  train_step_func = get_train_step_func()\n",
        "  training_loss = []\n",
        "  validation_loss = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "      batch_loss = train_step_func(inp, targ, enc_hidden, encoder, decoder)\n",
        "      total_loss += batch_loss\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
        "        \n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_val_loss = 0\n",
        "    for (batch, (inp, targ)) in enumerate(validation_dataset.take(steps_per_epoch)):\n",
        "      val_loss = caculate_validation_loss(inp, targ, enc_hidden, encoder, decoder)\n",
        "      total_val_loss += val_loss\n",
        "\n",
        "    training_loss.append(total_loss / steps_per_epoch)\n",
        "    validation_loss.append(total_val_loss / steps_per_epoch_val)\n",
        "    print('Epoch {} Loss {:.4f} Validation Loss {:.4f}'.format(epoch + 1,\n",
        "                                        training_loss[-1], validation_loss[-1]))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "  return encoder, decoder, training_loss, validation_loss"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQKjqurFVY0u"
      },
      "source": [
        "## Training seq2seq with Bahdanau attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TUKivtyYix6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "outputId": "df347bf1-4a2e-4ef8-e58b-4f6d750e61f3"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "attention = BahdanauAttention(units)\n",
        "print(\"Running seq2seq model with Bahdanau attention\")\n",
        "encoder_bah, decoder_bah, training_loss, validation_loss = training_seq2seq(epochs, attention)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running seq2seq model with Bahdanau attention\n",
            "Epoch 1 Batch 0 Loss 2.8979\n",
            "Epoch 1 Loss 2.6026 Validation Loss 2.3051\n",
            "Time taken for 1 epoch 85.2699625492096 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.2474\n",
            "Epoch 2 Loss 2.1109 Validation Loss 2.1039\n",
            "Time taken for 1 epoch 42.50201988220215 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.1374\n",
            "Epoch 3 Loss 1.9659 Validation Loss 2.0046\n",
            "Time taken for 1 epoch 42.50455117225647 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.9448\n",
            "Epoch 4 Loss 1.8813 Validation Loss 1.9585\n",
            "Time taken for 1 epoch 42.47143340110779 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.7290\n",
            "Epoch 5 Loss 1.7933 Validation Loss 1.8650\n",
            "Time taken for 1 epoch 43.07177925109863 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.7711\n",
            "Epoch 6 Loss 1.7042 Validation Loss 1.8502\n",
            "Time taken for 1 epoch 42.372519969940186 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.6046\n",
            "Epoch 7 Loss 1.6103 Validation Loss 1.7795\n",
            "Time taken for 1 epoch 42.26524758338928 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.4092\n",
            "Epoch 8 Loss 1.5142 Validation Loss 1.7595\n",
            "Time taken for 1 epoch 42.23895788192749 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.4105\n",
            "Epoch 9 Loss 1.4332 Validation Loss 1.7447\n",
            "Time taken for 1 epoch 42.40958309173584 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.3558\n",
            "Epoch 10 Loss 1.3527 Validation Loss 1.7135\n",
            "Time taken for 1 epoch 42.20034718513489 sec\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-58102cf5c409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder_bah\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_bah\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_seq2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mvloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tloss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1DBwgDpt0-u"
      },
      "source": [
        "tloss = np.vstack((tloss, training_loss))\n",
        "vloss = np.vstack((vloss, validation_loss))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "QTf_wW9jvTyq",
        "outputId": "34d7b2d2-12a0-4bf3-b15c-2a048da3877e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.arange(10), np.array(validation_loss))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4b763190d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBeMYwpMOPyI"
      },
      "source": [
        "# Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad9Fn5HrOO6i"
      },
      "source": [
        "def translate(sentence, encoder, decoder):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    # until the predicted word is <end>.\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence\n",
        "\n",
        "    # the predicted ID is fed back into the model, no teacher forcing.\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "CKYpv1y8wbYP",
        "outputId": "b322fdf4-46c4-440f-f3a4-0b16ad3b9168"
      },
      "source": [
        "df.iloc[500,2]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Beyoncé has received praise for her stage presence and voice during live performances. Jarett Wieselman of the New York Post placed her at number one on her list of the Five Best Singer/Dancers. According to Barbara Ellen of The Guardian Beyoncé is the most in-charge female artist she\\'s seen onstage, while Alice Jones of The Independent wrote she \"takes her role as entertainer so seriously she\\'s almost too good.\" The ex-President of Def Jam L.A. Reid has described Beyoncé as the greatest entertainer alive. Jim Farber of the Daily News and Stephanie Classen of Star Phoenix both praised her strong voice and her stage presence.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmPB_EoAWxKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04cbdae-7dbe-44d9-b67b-a17b478fd64b"
      },
      "source": [
        "result, sentence = translate(u'Beyonce was born in 1950', encoder_bah, decoder_bah)\n",
        "print('Input: %s' % (sentence))\n",
        "print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> beyonce was born in <end>\n",
            "Predicted translation: what was the name of the name of the name of the name of the name of the film ? <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhfNXw_Sx-vl"
      },
      "source": [
        "# Graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw9uzh3zyU9z"
      },
      "source": [
        "def evaluate(sentence, target_sentence_tokenizer,max_target_length, max_source_length, source_sentence_tokenizer):\n",
        "    attention_plot= np.zeros((max_target_length, max_source_length))\n",
        "    #preprocess the sentnece\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    #convert the sentence to index based on word2index dictionary\n",
        "    inputs= [source_sentence_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "\n",
        "    # pad the sequence \n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_source_length, padding='post')\n",
        "\n",
        "    #conver to tensors\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result= ''\n",
        "\n",
        "    # creating encoder\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    encoder_output, encoder_hidden= encoder(inputs, hidden)\n",
        "\n",
        "    # creating decoder\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_input = tf.expand_dims([target_sentence_tokenizer.word_index['start']], 0)\n",
        "    for t in range(max_target_length):\n",
        "        predictions, decoder_hidden, attention_weights= decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "\n",
        "        # storing attention weight for plotting it\n",
        "        attention_weights = tf.reshape(attention_weights, (-1,))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        prediction_id= tf.argmax(predictions[0]).numpy()\n",
        "        result += target_sentence_tokenizer.index_word[prediction_id] + ' '\n",
        "\n",
        "        if target_sentence_tokenizer.index_word[prediction_id] == '_end':\n",
        "            return result,sentence, attention_plot\n",
        "\n",
        "        # predicted id is fed back to as input to the decoder\n",
        "        decoder_input = tf.expand_dims([prediction_id], 0)\n",
        "\n",
        "    return result,sentence, attention_plot\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax= fig.add_subplot(1,1,1)\n",
        "    ax.matshow(attention, cmap='Greens')\n",
        "    fontdict={'fontsize':10}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkAKx0xNyPw8"
      },
      "source": [
        "def question(sentence, target_sentence_tokenizer,max_target_length, max_source_length, source_sentence_tokenizer ):\n",
        "    result, sentence, attention_plot = evaluate(sentence,target_sentence_tokenizer,max_target_length, max_source_length, source_sentence_tokenizer)\n",
        "\n",
        "    print('Input : %s' % (sentence))\n",
        "    print('predicted sentence :{}'.format(result))\n",
        "\n",
        "    attention_plot= attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "xHagXpnjyPrN",
        "outputId": "3e662970-1239-4dba-b1be-1694193badbb"
      },
      "source": [
        "question(\"Beyonce was born in 1955\", targ_lang,max_length_targ, max_length_inp, inp_lang)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-6b9600cd5ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Beyonce was born in 1955\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lang\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length_targ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-90-f3f4838e81c1>\u001b[0m in \u001b[0;36mquestion\u001b[0;34m(sentence, target_sentence_tokenizer, max_target_length, max_source_length, source_sentence_tokenizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sentence_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_target_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_source_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sentence_tokenizer\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_sentence_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_target_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_source_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sentence_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input : %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted sentence :{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-b3390a0ed785>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence, target_sentence_tokenizer, max_target_length, max_source_length, source_sentence_tokenizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_sentence_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_target_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# storing attention weight for plotting it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'decoder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "d57ML8nayPpZ",
        "outputId": "5f0e7806-176c-4111-9f1c-da0c90f223ce"
      },
      "source": [
        "attention.attention"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-79bf50f4aea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'BahdanauAttention' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqpTUOKq11ej"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}